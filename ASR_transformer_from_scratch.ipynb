{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zSK3BhIPVNs2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(layers.Layer):\n",
        "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
        "        super().__init__()\n",
        "        self.emb = keras.layers.Embedding(num_vocab, num_hid)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        x = self.emb(x)\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "class SpeechFeatureEmbedding(layers.Layer):\n",
        "    def __init__(self, num_hid=64, maxlen=100):\n",
        "        super().__init__()\n",
        "        self.conv1 = keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv2 = keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "        self.conv3 = keras.layers.Conv1D(\n",
        "            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return self.conv3(x)"
      ],
      "metadata": {
        "id": "-RWZox9tVn7T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "eGO0j6d2VxfS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.self_att = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.self_dropout = layers.Dropout(0.5)\n",
        "        self.enc_dropout = layers.Dropout(0.1)\n",
        "        self.ffn_dropout = layers.Dropout(0.1)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
        "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
        "\n",
        "        This prevents flow of information from future tokens to current token.\n",
        "        1's in the lower triangle, counting from the lower right corner.\n",
        "        \"\"\"\n",
        "        i = tf.range(n_dest)[:, None]\n",
        "        j = tf.range(n_src)\n",
        "        m = i >= j - n_src + n_dest\n",
        "        mask = tf.cast(m, dtype)\n",
        "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, enc_out, target):\n",
        "        input_shape = tf.shape(target)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        target_att = self.self_att(target, target, attention_mask=causal_mask)\n",
        "        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n",
        "        enc_out = self.enc_att(target_norm, enc_out)\n",
        "        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n",
        "        ffn_out = self.ffn(enc_out_norm)\n",
        "        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n",
        "        return ffn_out_norm"
      ],
      "metadata": {
        "id": "PVxKj-0MV2JU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_hid=64,\n",
        "        num_head=2,\n",
        "        num_feed_forward=128,\n",
        "        source_maxlen=100,\n",
        "        target_maxlen=100,\n",
        "        num_layers_enc=4,\n",
        "        num_layers_dec=1,\n",
        "        num_classes=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n",
        "        self.num_layers_enc = num_layers_enc\n",
        "        self.num_layers_dec = num_layers_dec\n",
        "        self.target_maxlen = target_maxlen\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.enc_input = SpeechFeatureEmbedding(num_hid=num_hid, maxlen=source_maxlen)\n",
        "        self.dec_input = TokenEmbedding(\n",
        "            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n",
        "        )\n",
        "\n",
        "        self.encoder = keras.Sequential(\n",
        "            [self.enc_input]\n",
        "            + [\n",
        "                TransformerEncoder(num_hid, num_head, num_feed_forward)\n",
        "                for _ in range(num_layers_enc)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(num_layers_dec):\n",
        "            setattr(\n",
        "                self,\n",
        "                f\"dec_layer_{i}\",\n",
        "                TransformerDecoder(num_hid, num_head, num_feed_forward),\n",
        "            )\n",
        "\n",
        "        self.classifier = layers.Dense(num_classes)\n",
        "\n",
        "    def decode(self, enc_out, target):\n",
        "        y = self.dec_input(target)\n",
        "        for i in range(self.num_layers_dec):\n",
        "            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n",
        "        return y\n",
        "\n",
        "    def call(self, inputs):\n",
        "        source = inputs[0]\n",
        "        target = inputs[1]\n",
        "        x = self.encoder(source)\n",
        "        y = self.decode(x, target)\n",
        "        return self.classifier(y)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_metric]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        \"\"\"Processes one batch inside model.fit().\"\"\"\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds = self([source, dec_input])\n",
        "            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "            loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        source = batch[\"source\"]\n",
        "        target = batch[\"target\"]\n",
        "        dec_input = target[:, :-1]\n",
        "        dec_target = target[:, 1:]\n",
        "        preds = self([source, dec_input])\n",
        "        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n",
        "        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n",
        "        loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n",
        "        self.loss_metric.update_state(loss)\n",
        "        return {\"loss\": self.loss_metric.result()}\n",
        "\n",
        "    def generate(self, source, target_start_token_idx):\n",
        "        \"\"\"Performs inference over one batch of inputs using greedy decoding.\"\"\"\n",
        "        bs = tf.shape(source)[0]\n",
        "        enc = self.encoder(source)\n",
        "        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n",
        "        dec_logits = []\n",
        "        for i in range(self.target_maxlen - 1):\n",
        "            dec_out = self.decode(enc, dec_input)\n",
        "            logits = self.classifier(dec_out)\n",
        "            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n",
        "            dec_logits.append(last_logit)\n",
        "            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n",
        "        return dec_input"
      ],
      "metadata": {
        "id": "nlm52fNaV6bT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.get_file(\n",
        "    os.path.join(os.getcwd(), \"data.tar.gz\"),\n",
        "    \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\",\n",
        "    extract=True,\n",
        "    archive_format=\"tar\",\n",
        "    cache_dir=\".\",\n",
        ")\n",
        "\n",
        "\n",
        "saveto = \"./datasets/LJSpeech-1.1\"\n",
        "wavs = glob(\"{}/**/*.wav\".format(saveto), recursive=True)\n",
        "\n",
        "id_to_text = {}\n",
        "with open(os.path.join(saveto, \"metadata.csv\"), encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        id = line.strip().split(\"|\")[0]\n",
        "        text = line.strip().split(\"|\")[2]\n",
        "        id_to_text[id] = text\n",
        "\n",
        "\n",
        "def get_data(wavs, id_to_text, maxlen=50):\n",
        "    \"\"\"returns mapping of audio paths and transcription texts\"\"\"\n",
        "    data = []\n",
        "    for w in wavs:\n",
        "        id = w.split(\"/\")[-1].split(\".\")[0]\n",
        "        if len(id_to_text[id]) < maxlen:\n",
        "            data.append({\"audio\": w, \"text\": id_to_text[id]})\n",
        "    return data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH02Fb9LWATd",
        "outputId": "496ab471-de65-4413-81c3-320906621c52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "\u001b[1m2748572632/2748572632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorizeChar:\n",
        "    def __init__(self, max_len=50):\n",
        "        self.vocab = (\n",
        "            [\"-\", \"#\", \"<\", \">\"]\n",
        "            + [chr(i + 96) for i in range(1, 27)]\n",
        "            + [\" \", \".\", \",\", \"?\"]\n",
        "        )\n",
        "        self.max_len = max_len\n",
        "        self.char_to_idx = {}\n",
        "        for i, ch in enumerate(self.vocab):\n",
        "            self.char_to_idx[ch] = i\n",
        "\n",
        "    def __call__(self, text):\n",
        "        text = text.lower()\n",
        "        text = text[: self.max_len - 2]\n",
        "        text = \"<\" + text + \">\"\n",
        "        pad_len = self.max_len - len(text)\n",
        "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
        "\n",
        "    def get_vocabulary(self):\n",
        "        return self.vocab\n",
        "\n",
        "\n",
        "max_target_len = 200  # all transcripts in out data are < 200 characters\n",
        "data = get_data(wavs, id_to_text, max_target_len)\n",
        "vectorizer = VectorizeChar(max_target_len)\n",
        "print(\"vocab size\", len(vectorizer.get_vocabulary()))\n",
        "\n",
        "\n",
        "def create_text_ds(data):\n",
        "    texts = [_[\"text\"] for _ in data]\n",
        "    text_ds = [vectorizer(t) for t in texts]\n",
        "    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n",
        "    return text_ds\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    # spectrogram using stft\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
        "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
        "    # normalisation\n",
        "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
        "    x = (x - means) / stddevs\n",
        "    audio_len = tf.shape(x)[0]\n",
        "    # padding to 10 seconds\n",
        "    pad_len = 2754\n",
        "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
        "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_audio_ds(data):\n",
        "    flist = [_[\"audio\"] for _ in data]\n",
        "    audio_ds = tf.data.Dataset.from_tensor_slices(flist)\n",
        "    audio_ds = audio_ds.map(path_to_audio, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return audio_ds\n",
        "\n",
        "\n",
        "def create_tf_dataset(data, bs=4):\n",
        "    audio_ds = create_audio_ds(data)\n",
        "    text_ds = create_text_ds(data)\n",
        "    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n",
        "    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n",
        "    ds = ds.batch(bs)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "\n",
        "split = int(len(data) * 0.99)\n",
        "train_data = data[:split]\n",
        "test_data = data[split:]\n",
        "ds = create_tf_dataset(train_data, bs=64)\n",
        "val_ds = create_tf_dataset(test_data, bs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9cs0udeWN7L",
        "outputId": "8720373a-70ed-4cf7-b000-8425afb2c544"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayOutputs(keras.callbacks.Callback):\n",
        "    def __init__(\n",
        "        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n",
        "    ):\n",
        "        \"\"\"Displays a batch of outputs after every epoch\n",
        "\n",
        "        Args:\n",
        "            batch: A test batch containing the keys \"source\" and \"target\"\n",
        "            idx_to_token: A List containing the vocabulary tokens corresponding to their indices\n",
        "            target_start_token_idx: A start token index in the target vocabulary\n",
        "            target_end_token_idx: An end token index in the target vocabulary\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "        self.target_start_token_idx = target_start_token_idx\n",
        "        self.target_end_token_idx = target_end_token_idx\n",
        "        self.idx_to_char = idx_to_token\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % 5 != 0:\n",
        "            return\n",
        "        source = self.batch[\"source\"]\n",
        "        target = self.batch[\"target\"].numpy()\n",
        "        bs = tf.shape(source)[0]\n",
        "        preds = self.model.generate(source, self.target_start_token_idx)\n",
        "        preds = preds.numpy()\n",
        "        for i in range(bs):\n",
        "            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n",
        "            prediction = \"\"\n",
        "            for idx in preds[i, :]:\n",
        "                prediction += self.idx_to_char[idx]\n",
        "                if idx == self.target_end_token_idx:\n",
        "                    break\n",
        "            print(f\"target:     {target_text.replace('-','')}\")\n",
        "            print(f\"prediction: {prediction}\\n\")"
      ],
      "metadata": {
        "id": "rWXODnO8WgxD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        init_lr=0.00001,\n",
        "        lr_after_warmup=0.001,\n",
        "        final_lr=0.00001,\n",
        "        warmup_epochs=15,\n",
        "        decay_epochs=85,\n",
        "        steps_per_epoch=203,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.init_lr = init_lr\n",
        "        self.lr_after_warmup = lr_after_warmup\n",
        "        self.final_lr = final_lr\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.decay_epochs = decay_epochs\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "    def calculate_lr(self, epoch):\n",
        "        \"\"\"linear warm up - linear decay\"\"\"\n",
        "        warmup_lr = (\n",
        "            self.init_lr\n",
        "            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n",
        "        )\n",
        "        decay_lr = tf.math.maximum(\n",
        "            self.final_lr,\n",
        "            self.lr_after_warmup\n",
        "            - (epoch - self.warmup_epochs)\n",
        "            * (self.lr_after_warmup - self.final_lr)\n",
        "            / self.decay_epochs,\n",
        "        )\n",
        "        return tf.math.minimum(warmup_lr, decay_lr)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        epoch = step // self.steps_per_epoch\n",
        "        epoch = tf.cast(epoch, \"float32\")\n",
        "        return self.calculate_lr(epoch)"
      ],
      "metadata": {
        "id": "qvvHzzwtWk3D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(val_ds))\n",
        "\n",
        "# The vocabulary to convert predicted indices into characters\n",
        "idx_to_char = vectorizer.get_vocabulary()\n",
        "display_cb = DisplayOutputs(\n",
        "    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n",
        ")  # set the arguments as per vocabulary index for '<' and '>'\n",
        "\n",
        "model = Transformer(\n",
        "    num_hid=200,\n",
        "    num_head=2,\n",
        "    num_feed_forward=400,\n",
        "    target_maxlen=max_target_len,\n",
        "    num_layers_enc=4,\n",
        "    num_layers_dec=1,\n",
        "    num_classes=34,\n",
        ")\n",
        "loss_fn = keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    label_smoothing=0.1,\n",
        ")\n",
        "\n",
        "learning_rate = CustomSchedule(\n",
        "    init_lr=0.00001,\n",
        "    lr_after_warmup=0.001,\n",
        "    final_lr=0.00001,\n",
        "    warmup_epochs=15,\n",
        "    decay_epochs=85,\n",
        "    steps_per_epoch=len(ds),\n",
        ")\n",
        "optimizer = keras.optimizers.Adam(learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "history = model.fit(ds, validation_data=val_ds, callbacks=[display_cb], epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE68XlejWprD",
        "outputId": "38e4bfe7-0e72-4879-c815-edd7dfe1550d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - loss: 1.8327"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (4, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <the athe the an there the are the the iof one ar ar at s t t the asin as the t wathe a an ond ane at in the e t the the the se the e s at ten t the ar t here the the tof terint wathe theere the the t\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <the athe the an there the are the the iof one ar ar at s t t the asin as the t wathe a an ond ane at in the e t the the the s a in e s are t the ond t t here the the tof terint wathe theere the the t\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <the athe the an there the are the the iof one ar ar at s t t the asin as the t wathe a an ond ane at in the e t the the the s a in e s at ten t the ar t here the the tof terint wathe theere the the t\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the athe the an there the are the the iof one ar ar at s t t the asin as the t wathe a an ond ane at in the e t the the the s a in e s at ten t the ar t here the the tof terint wathe theere the the t\n",
            "\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 642ms/step - loss: 1.8318 - val_loss: 1.5101\n",
            "Epoch 2/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 506ms/step - loss: 1.3886 - val_loss: 1.3612\n",
            "Epoch 3/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 497ms/step - loss: 1.3187 - val_loss: 1.3391\n",
            "Epoch 4/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 489ms/step - loss: 1.3030 - val_loss: 1.3307\n",
            "Epoch 5/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 479ms/step - loss: 1.2933 - val_loss: 1.3173\n",
            "Epoch 6/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - loss: 1.2714target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <as the the sere the sisiore the the the siore the the the the sisiore assin the the the asin the the sasisiore an the tore the the asiore the.>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <and the sthere are the the the the the sthe are the the there are the the the the the the the the the there the there t.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some the sof the se ane the the ane asthe and and the asthe and the the sthe the ande the the the sthe the the ane asthe the the sthe sthe the athe athe the sthe the te tent tennedy.>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <they ale the the ale the fof the the the ale ale ale the the as the the the the the the the alathe the the ore allale the the the the the the the ofofofofofore the the thent tennedy.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 526ms/step - loss: 1.2714 - val_loss: 1.2772\n",
            "Epoch 7/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 486ms/step - loss: 1.2296 - val_loss: 1.2149\n",
            "Epoch 8/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 480ms/step - loss: 1.1592 - val_loss: 1.1058\n",
            "Epoch 9/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 489ms/step - loss: 1.0321 - val_loss: 0.9564\n",
            "Epoch 10/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 487ms/step - loss: 0.8906 - val_loss: 0.8573\n",
            "Epoch 11/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step - loss: 0.8025target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <as serious din and the assassination and and and and and and and and and and and and the assassination,>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <after and not haper his deempacked frapacked acked it of acked it of acked acked it of ackeged in not backed apacket.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <somolving that fiel cand by cand volving that fiel cand by cand by cand by then sixty cand by cand by cand buring tion cherenthe theng by theuren,>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the immunion, platity leation, platity leation, platity lin leation, platity ling lin lin lin leation fank lin lin lin lin lin lin lin lin t lin f lin ly le the lin the ling lennothelellin lllimelime\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 520ms/step - loss: 0.8025 - val_loss: 0.8092\n",
            "Epoch 12/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 480ms/step - loss: 0.7518 - val_loss: 0.7788\n",
            "Epoch 13/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 483ms/step - loss: 0.7148 - val_loss: 0.7489\n",
            "Epoch 14/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 485ms/step - loss: 0.6841 - val_loss: 0.7372\n",
            "Epoch 15/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 488ms/step - loss: 0.6604 - val_loss: 0.7224\n",
            "Epoch 16/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step - loss: 0.6433target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <a series of teseries of tests in the assassination and and and and and and and and and and and and and and and and and and then>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <after and not the backaged on the backaged on the backaged on the backaged on the car and not the backage on the backarounoute.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some of that fential campain the in the in the insixty campain sixty campain sixted in the in volving was expresed in tentheng ing the the sthe the athe calvong>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the and lee chotitited hand lee chotith and lee chotith and lose attiter with and loselves after the rown faship of and lingling lling ond linglind llinglingling f.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 516ms/step - loss: 0.6433 - val_loss: 0.7040\n",
            "Epoch 17/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 484ms/step - loss: 0.6209 - val_loss: 0.6975\n",
            "Epoch 18/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 476ms/step - loss: 0.6026 - val_loss: 0.6769\n",
            "Epoch 19/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 479ms/step - loss: 0.5855 - val_loss: 0.6778\n",
            "Epoch 20/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 474ms/step - loss: 0.5720 - val_loss: 0.6653\n",
            "Epoch 21/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step - loss: 0.5553target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <assaning useries of tests in the assassination and and and and and and and and and and and and and and and and and and and and and an>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <aftered lanced abrown package seet abrown package the car an not the backage the cage the cage on the backage cage the cagutis te.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some of that feeling the insixted in the insixtedential campain the insixtedential campain the insixtedential campain the inteeential campaing>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the imme ymy lon fanker than leety long fand line men the chotity long fanker thanker thank blinds bottit hand line mends botit he row ar be linend meme fath.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 506ms/step - loss: 0.5553 - val_loss: 0.6410\n",
            "Epoch 22/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 481ms/step - loss: 0.5309 - val_loss: 0.6180\n",
            "Epoch 23/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 482ms/step - loss: 0.5101 - val_loss: 0.5967\n",
            "Epoch 24/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 484ms/step - loss: 0.4949 - val_loss: 0.5824\n",
            "Epoch 25/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 481ms/step - loss: 0.4827 - val_loss: 0.5809\n",
            "Epoch 26/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.4750target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <a series of tests weries of tests were appen and and and and and and and and and and and and and and and and and and and assassination,>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <after and to is to is to is to is to is to is to is to abround package on the back cear, frazier frazier debround packed.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some of that feeling was expressed in the ineteen sixted in the ineteen sixteed john nineteen sixteed john ninetial canded a jonson, during during the ning,>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the amuse themselved of engs boven plation, plation, plate fraugh fashion, plation, plation, plation, plation, plation, plation, pline line line line line ly lly.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 516ms/step - loss: 0.4750 - val_loss: 0.5825\n",
            "Epoch 27/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 483ms/step - loss: 0.4685 - val_loss: 0.5694\n",
            "Epoch 28/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 476ms/step - loss: 0.4570 - val_loss: 0.5676\n",
            "Epoch 29/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 479ms/step - loss: 0.4508 - val_loss: 0.5589\n",
            "Epoch 30/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 487ms/step - loss: 0.4444 - val_loss: 0.5587\n",
            "Epoch 31/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - loss: 0.4380target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <a series of tes were preformed to detests were preformed to detests were preformed to detests were proformed to detests were preformed to detests inthe assann>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <after entering the car frazier frazier frazier frazier frazier frazier frazier frazier frazier frazier frazier frazier enter entering the car ent>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some of that feeling was expresident involving was expresident involving was expresident in the incident in the ineteential candaday adjohnson,>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the immuse the immuse themselves aute her with ankerchiffashion, or beat he not it hankerchiff,>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 512ms/step - loss: 0.4381 - val_loss: 0.5589\n",
            "Epoch 32/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 481ms/step - loss: 0.4337 - val_loss: 0.5506\n",
            "Epoch 33/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 489ms/step - loss: 0.4312 - val_loss: 0.5564\n",
            "Epoch 34/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 493ms/step - loss: 0.4254 - val_loss: 0.5522\n",
            "Epoch 35/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 486ms/step - loss: 0.4222 - val_loss: 0.5515\n",
            "Epoch 36/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - loss: 0.4190target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <asseries of tests were proformed to determine whether the weapon and amunition,>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <after antering the car frazier glanced on the backage on the car frazier frazier glanced on the car frazier glanced on the car frazier glanced.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some of that feeling then sixty campain, during then volving was expresident in the involving was expresidential campain,>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the immuse the rown fashifter the row fand lee ach other with ankrotuate hankrotuate hankrotuate her with ankerchif.>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 516ms/step - loss: 0.4190 - val_loss: 0.5406\n",
            "Epoch 37/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 484ms/step - loss: 0.4142 - val_loss: 0.5476\n",
            "Epoch 38/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 480ms/step - loss: 0.4130 - val_loss: 0.5425\n",
            "Epoch 39/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 477ms/step - loss: 0.4076 - val_loss: 0.5384\n",
            "Epoch 40/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 478ms/step - loss: 0.4077 - val_loss: 0.5333\n",
            "Epoch 41/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - loss: 0.4227target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <a series of tests were proformed to determine ws din the assassination and amunistion and amunist used in the assassination>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <after antering the car frazier frazier frazier frazier frazier frazier frazier frazier frazier fazier frazier frazier frazier fazured lantering the.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some of that feeling was expressed in the ineteen sixty campain six president in the ineteen sixty campain, during then sixty campaing,>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the immuse the muse themselves after the row fashiphed fraug, plaine mews themselves after the row fashiph,>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 511ms/step - loss: 0.4227 - val_loss: 0.5313\n",
            "Epoch 42/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 480ms/step - loss: 0.4051 - val_loss: 0.5299\n",
            "Epoch 43/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 491ms/step - loss: 0.4028 - val_loss: 0.5362\n",
            "Epoch 44/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 483ms/step - loss: 0.3971 - val_loss: 0.5349\n",
            "Epoch 45/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 493ms/step - loss: 0.3914 - val_loss: 0.5364\n",
            "Epoch 46/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.3882target:     <a series of tests were performed to determine whether the weapon and ammunition used in the assassination>\n",
            "prediction: <asseries of tests were performed to getests were performed to getests were performed to getests were performed to determined>\n",
            "\n",
            "target:     <after entering the car, frazier glanced over his shoulder and noticed a brown paper package on the back seat.>\n",
            "prediction: <aftering the car frazier glanst over his houlder and noticed a bround package on the bag ceate on the bag ceate.>\n",
            "\n",
            "target:     <some of that feeling was expressed in the incident involving then vicepresidential candidate johnson during the nineteen sixty campaign,>\n",
            "prediction: <some of that feeeling was expressed in the incident in the incident in the incidential campain six presidential campain,>\n",
            "\n",
            "target:     <they amused themselves after their own fashion# played all day long at blindman#sbuff and leapfrog, or beat each other with a knotted handkerchief,>\n",
            "prediction: <the immus themselves after the rown fashiff,>\n",
            "\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 519ms/step - loss: 0.3882 - val_loss: 0.5328\n",
            "Epoch 47/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 484ms/step - loss: 0.3852 - val_loss: 0.5356\n",
            "Epoch 48/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 483ms/step - loss: 0.3845 - val_loss: 0.5379\n",
            "Epoch 49/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 483ms/step - loss: 0.3821 - val_loss: 0.5346\n",
            "Epoch 50/50\n",
            "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 480ms/step - loss: 0.3807 - val_loss: 0.5337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the audio preprocessing function\n",
        "def preprocess_audio(file_path):\n",
        "    audio = tf.io.read_file(file_path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n",
        "    x = tf.math.pow(tf.abs(stfts), 0.5)\n",
        "    # normalisation\n",
        "    means = tf.math.reduce_mean(x, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n",
        "    x = (x - means) / stddevs\n",
        "    pad_len = 2754\n",
        "    paddings = tf.constant([[0, pad_len], [0, 0]])\n",
        "    x = tf.pad(x, paddings, \"CONSTANT\")[:pad_len, :]\n",
        "    return tf.expand_dims(x, axis=0)  # Add batch dimension\n",
        "\n",
        "# Load your audio file\n",
        "audio_input = preprocess_audio(\"/content/datasets/LJSpeech-1.1/wavs/LJ001-0053.wav\")\n"
      ],
      "metadata": {
        "id": "mfKMt38yXaCG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start token index (as per your vocabulary, e.g., \"<\")\n",
        "target_start_token_idx = 27  # Adjust according to your actual token index\n",
        "\n",
        "# Perform inference\n",
        "predicted_tokens = model.generate(audio_input, target_start_token_idx)\n",
        "\n",
        "# Convert the token indices to characters\n",
        "idx_to_token = vectorizer.get_vocabulary()  # Load the vocabulary mapping\n",
        "predicted_text = \"\".join([idx_to_token[idx] for idx in predicted_tokens[0] if idx > 0])\n",
        "\n",
        "# Output the predicted text\n",
        "print(\"Predicted transcription:\", predicted_text)"
      ],
      "metadata": {
        "id": "UzgQ0vk3YtZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqiZNyHsuH-Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}